{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io.arff import loadarff \n",
    "\n",
    "from sklearn.model_selection import(\n",
    "    train_test_split, \n",
    "    cross_val_predict,\n",
    "    KFold,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import (\n",
    "    Dataset, \n",
    "    DataLoader,\n",
    "    TensorDataset,\n",
    "    random_split,\n",
    "    SubsetRandomSampler,\n",
    "    ConcatDataset,\n",
    ")\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU HELL YEAH!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling on GPU, babe\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "        print('Rolling on GPU, babe')\n",
    "        return device\n",
    "    print('CPU it is...')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "raw_data = loadarff('mnist_784.arff')\n",
    "df = pd.DataFrame(raw_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validação\n",
    "portion_to_validate = 0.1\n",
    "df_validation = df.sample(frac = portion_to_validate)\n",
    "df = df.drop(df_validation.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train_epoch(net, device, dataloader, loss_fn, optimizer):\n",
    "    net.train()\n",
    "    for X, y in dataloader:\n",
    "        y = y.type(torch.LongTensor)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = net(X)\n",
    "        loss = loss_fn(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def valid_epoch(net, device, dataloader, loss_fn):\n",
    "    valid_loss, val_correct = 0.0, 0\n",
    "    net.eval()\n",
    "    for X, y in dataloader:\n",
    "        y = y.type(torch.LongTensor)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        output = net(X)\n",
    "        loss=loss_fn(output, y)\n",
    "        scores, predictions = torch.max(output.data,1)\n",
    "        val_correct += (predictions == y).sum().item()\n",
    "\n",
    "    return loss, val_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MD(Dataset):\n",
    " \n",
    "  def __init__(self, X, y):\n",
    "    self.X_train = torch.tensor(X.values, dtype=torch.float)\n",
    "    self.y_train = torch.tensor(y.values.flatten(), dtype=torch.float)\n",
    " \n",
    "  def __len__(self):\n",
    "    return len(self.y_train)\n",
    "   \n",
    "  def __getitem__(self,idx):\n",
    "    return self.X_train[idx], self.y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch: 1/10 Training Loss: 0.169 \t Test Accuracy: 0.9466666666666667\n",
      "Epoch: 2/10 Training Loss: 0.178 \t Test Accuracy: 0.9623809523809523\n",
      "Epoch: 3/10 Training Loss: 0.057 \t Test Accuracy: 0.9653968253968254\n",
      "Epoch: 4/10 Training Loss: 0.047 \t Test Accuracy: 0.9503174603174603\n",
      "Epoch: 5/10 Training Loss: 0.167 \t Test Accuracy: 0.966031746031746\n",
      "Epoch: 6/10 Training Loss: 0.037 \t Test Accuracy: 0.9655555555555555\n",
      "Epoch: 7/10 Training Loss: 0.015 \t Test Accuracy: 0.967936507936508\n",
      "Epoch: 8/10 Training Loss: 0.008 \t Test Accuracy: 0.9736507936507937\n",
      "Epoch: 9/10 Training Loss: 0.160 \t Test Accuracy: 0.9588888888888889\n",
      "Epoch: 10/10 Training Loss: 0.040 \t Test Accuracy: 0.9696825396825397\n",
      "Fold 2\n",
      "Epoch: 1/10 Training Loss: 0.276 \t Test Accuracy: 0.9512698412698413\n",
      "Epoch: 2/10 Training Loss: 0.148 \t Test Accuracy: 0.9488888888888889\n",
      "Epoch: 3/10 Training Loss: 0.238 \t Test Accuracy: 0.9593650793650793\n",
      "Epoch: 4/10 Training Loss: 0.150 \t Test Accuracy: 0.9542857142857143\n",
      "Epoch: 5/10 Training Loss: 0.030 \t Test Accuracy: 0.9668253968253968\n",
      "Epoch: 6/10 Training Loss: 0.015 \t Test Accuracy: 0.9673015873015873\n",
      "Epoch: 7/10 Training Loss: 0.072 \t Test Accuracy: 0.9682539682539683\n",
      "Epoch: 8/10 Training Loss: 0.020 \t Test Accuracy: 0.9623809523809523\n",
      "Epoch: 9/10 Training Loss: 0.041 \t Test Accuracy: 0.9684126984126984\n",
      "Epoch: 10/10 Training Loss: 0.021 \t Test Accuracy: 0.9677777777777777\n",
      "Fold 3\n",
      "Epoch: 1/10 Training Loss: 0.290 \t Test Accuracy: 0.9450793650793651\n",
      "Epoch: 2/10 Training Loss: 0.134 \t Test Accuracy: 0.9598412698412698\n",
      "Epoch: 3/10 Training Loss: 0.101 \t Test Accuracy: 0.9625396825396826\n",
      "Epoch: 4/10 Training Loss: 0.018 \t Test Accuracy: 0.9615873015873015\n",
      "Epoch: 5/10 Training Loss: 0.055 \t Test Accuracy: 0.96\n",
      "Epoch: 6/10 Training Loss: 0.040 \t Test Accuracy: 0.956031746031746\n",
      "Epoch: 7/10 Training Loss: 0.189 \t Test Accuracy: 0.9585714285714285\n",
      "Epoch: 8/10 Training Loss: 0.001 \t Test Accuracy: 0.966031746031746\n",
      "Epoch: 9/10 Training Loss: 0.007 \t Test Accuracy: 0.9668253968253968\n",
      "Epoch: 10/10 Training Loss: 0.267 \t Test Accuracy: 0.9625396825396826\n",
      "Fold 4\n",
      "Epoch: 1/10 Training Loss: 0.235 \t Test Accuracy: 0.9442857142857143\n",
      "Epoch: 2/10 Training Loss: 0.216 \t Test Accuracy: 0.9485714285714286\n",
      "Epoch: 3/10 Training Loss: 0.092 \t Test Accuracy: 0.9555555555555556\n",
      "Epoch: 4/10 Training Loss: 0.078 \t Test Accuracy: 0.9598412698412698\n",
      "Epoch: 5/10 Training Loss: 0.076 \t Test Accuracy: 0.9666666666666667\n",
      "Epoch: 6/10 Training Loss: 0.043 \t Test Accuracy: 0.9655555555555555\n",
      "Epoch: 7/10 Training Loss: 0.109 \t Test Accuracy: 0.9682539682539683\n",
      "Epoch: 8/10 Training Loss: 0.025 \t Test Accuracy: 0.9685714285714285\n",
      "Epoch: 9/10 Training Loss: 0.034 \t Test Accuracy: 0.9566666666666667\n",
      "Epoch: 10/10 Training Loss: 0.047 \t Test Accuracy: 0.9587301587301588\n",
      "Fold 5\n",
      "Epoch: 1/10 Training Loss: 0.219 \t Test Accuracy: 0.9455555555555556\n",
      "Epoch: 2/10 Training Loss: 0.155 \t Test Accuracy: 0.9577777777777777\n",
      "Epoch: 3/10 Training Loss: 0.167 \t Test Accuracy: 0.9577777777777777\n",
      "Epoch: 4/10 Training Loss: 0.105 \t Test Accuracy: 0.9568253968253968\n",
      "Epoch: 5/10 Training Loss: 0.030 \t Test Accuracy: 0.9625396825396826\n",
      "Epoch: 6/10 Training Loss: 0.008 \t Test Accuracy: 0.9646031746031746\n",
      "Epoch: 7/10 Training Loss: 0.031 \t Test Accuracy: 0.9633333333333334\n",
      "Epoch: 8/10 Training Loss: 0.131 \t Test Accuracy: 0.9614285714285714\n",
      "Epoch: 9/10 Training Loss: 0.069 \t Test Accuracy: 0.9665079365079365\n",
      "Epoch: 10/10 Training Loss: 0.114 \t Test Accuracy: 0.9615873015873015\n",
      "Fold 6\n",
      "Epoch: 1/10 Training Loss: 0.355 \t Test Accuracy: 0.9428571428571428\n",
      "Epoch: 2/10 Training Loss: 0.168 \t Test Accuracy: 0.9511111111111111\n",
      "Epoch: 3/10 Training Loss: 0.067 \t Test Accuracy: 0.9534920634920635\n",
      "Epoch: 4/10 Training Loss: 0.072 \t Test Accuracy: 0.9576190476190476\n",
      "Epoch: 5/10 Training Loss: 0.110 \t Test Accuracy: 0.9574603174603175\n",
      "Epoch: 6/10 Training Loss: 0.031 \t Test Accuracy: 0.9577777777777777\n",
      "Epoch: 7/10 Training Loss: 0.106 \t Test Accuracy: 0.9571428571428572\n",
      "Epoch: 8/10 Training Loss: 0.092 \t Test Accuracy: 0.9603174603174603\n",
      "Epoch: 9/10 Training Loss: 0.106 \t Test Accuracy: 0.966984126984127\n",
      "Epoch: 10/10 Training Loss: 0.174 \t Test Accuracy: 0.9565079365079365\n",
      "Fold 7\n",
      "Epoch: 1/10 Training Loss: 0.244 \t Test Accuracy: 0.9415873015873016\n",
      "Epoch: 2/10 Training Loss: 0.076 \t Test Accuracy: 0.9525396825396826\n",
      "Epoch: 3/10 Training Loss: 0.064 \t Test Accuracy: 0.9557142857142857\n",
      "Epoch: 4/10 Training Loss: 0.016 \t Test Accuracy: 0.9585714285714285\n",
      "Epoch: 5/10 Training Loss: 0.061 \t Test Accuracy: 0.9563492063492064\n",
      "Epoch: 6/10 Training Loss: 0.041 \t Test Accuracy: 0.9580952380952381\n",
      "Epoch: 7/10 Training Loss: 0.108 \t Test Accuracy: 0.9476190476190476\n",
      "Epoch: 8/10 Training Loss: 0.039 \t Test Accuracy: 0.9617460317460318\n",
      "Epoch: 9/10 Training Loss: 0.009 \t Test Accuracy: 0.9574603174603175\n",
      "Epoch: 10/10 Training Loss: 0.151 \t Test Accuracy: 0.9611111111111111\n",
      "Fold 8\n",
      "Epoch: 1/10 Training Loss: 0.333 \t Test Accuracy: 0.9471428571428572\n",
      "Epoch: 2/10 Training Loss: 0.175 \t Test Accuracy: 0.9466666666666667\n",
      "Epoch: 3/10 Training Loss: 0.095 \t Test Accuracy: 0.9553968253968254\n",
      "Epoch: 4/10 Training Loss: 0.152 \t Test Accuracy: 0.9531746031746032\n",
      "Epoch: 5/10 Training Loss: 0.018 \t Test Accuracy: 0.9615873015873015\n",
      "Epoch: 6/10 Training Loss: 0.094 \t Test Accuracy: 0.9587301587301588\n",
      "Epoch: 7/10 Training Loss: 0.192 \t Test Accuracy: 0.957936507936508\n",
      "Epoch: 8/10 Training Loss: 0.059 \t Test Accuracy: 0.9553968253968254\n",
      "Epoch: 9/10 Training Loss: 0.126 \t Test Accuracy: 0.9612698412698413\n",
      "Epoch: 10/10 Training Loss: 0.033 \t Test Accuracy: 0.9628571428571429\n",
      "Fold 9\n",
      "Epoch: 1/10 Training Loss: 0.215 \t Test Accuracy: 0.9461904761904761\n",
      "Epoch: 2/10 Training Loss: 0.271 \t Test Accuracy: 0.9514285714285714\n",
      "Epoch: 3/10 Training Loss: 0.229 \t Test Accuracy: 0.9511111111111111\n",
      "Epoch: 4/10 Training Loss: 0.107 \t Test Accuracy: 0.9512698412698413\n",
      "Epoch: 5/10 Training Loss: 0.063 \t Test Accuracy: 0.9620634920634921\n",
      "Epoch: 6/10 Training Loss: 0.072 \t Test Accuracy: 0.9596825396825397\n",
      "Epoch: 7/10 Training Loss: 0.009 \t Test Accuracy: 0.9644444444444444\n",
      "Epoch: 8/10 Training Loss: 0.111 \t Test Accuracy: 0.9663492063492064\n",
      "Epoch: 9/10 Training Loss: 0.027 \t Test Accuracy: 0.9646031746031746\n",
      "Epoch: 10/10 Training Loss: 0.002 \t Test Accuracy: 0.966984126984127\n",
      "Fold 10\n",
      "Epoch: 1/10 Training Loss: 0.129 \t Test Accuracy: 0.9603174603174603\n",
      "Epoch: 2/10 Training Loss: 0.107 \t Test Accuracy: 0.9603174603174603\n",
      "Epoch: 3/10 Training Loss: 0.132 \t Test Accuracy: 0.964920634920635\n",
      "Epoch: 4/10 Training Loss: 0.044 \t Test Accuracy: 0.9595238095238096\n",
      "Epoch: 5/10 Training Loss: 0.080 \t Test Accuracy: 0.9612698412698413\n",
      "Epoch: 6/10 Training Loss: 0.078 \t Test Accuracy: 0.9706349206349206\n",
      "Epoch: 7/10 Training Loss: 0.103 \t Test Accuracy: 0.9739682539682539\n",
      "Epoch: 8/10 Training Loss: 0.044 \t Test Accuracy: 0.9771428571428571\n",
      "Epoch: 9/10 Training Loss: 0.072 \t Test Accuracy: 0.9738095238095238\n",
      "Epoch: 10/10 Training Loss: 0.047 \t Test Accuracy: 0.976031746031746\n"
     ]
    }
   ],
   "source": [
    "# Separando dataset\n",
    "X = df.iloc[:, 0:-1]\n",
    "y = df.iloc[:, [-1]].astype('int')\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "EPOCHS = 10\n",
    "\n",
    "# Training the model\n",
    "fold = 0\n",
    "for train_index, test_index in kf.split(X, y):  \n",
    "    train = MD(X.iloc[train_index], y.iloc[train_index])\n",
    "    test = MD(X.iloc[test_index], y.iloc[test_index])\n",
    "\n",
    "    train_loader = DataLoader(train, batch_size=128)\n",
    "    test_loader = DataLoader(test, batch_size=128)\n",
    "\n",
    "    net = MLP().to(device)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    fold += 1\n",
    "    print(f'Fold {fold}')\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss = train_epoch(net, device, train_loader,\n",
    "                                F.nll_loss, optimizer)\n",
    "\n",
    "        test_loss, test_correct = valid_epoch(net, device, test_loader,\n",
    "                                F.nll_loss)\n",
    "\n",
    "        print(f'Epoch: {epoch+1}/{EPOCHS} Training Loss: {train_loss:.3f} \\t Test Accuracy: {test_correct/len(test_loader.sampler)}') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 Training Loss: 0.221\n",
      "Epoch: 2/10 Training Loss: 0.030\n",
      "Epoch: 3/10 Training Loss: 0.010\n",
      "Epoch: 4/10 Training Loss: 0.006\n",
      "Epoch: 5/10 Training Loss: 0.070\n",
      "Epoch: 6/10 Training Loss: 0.061\n",
      "Epoch: 7/10 Training Loss: 0.000\n",
      "Epoch: 8/10 Training Loss: 0.656\n",
      "Epoch: 9/10 Training Loss: 0.000\n",
      "Epoch: 10/10 Training Loss: 0.031\n"
     ]
    }
   ],
   "source": [
    "# Validations\n",
    "X_train = df.iloc[:, 0:-1]\n",
    "y_train = df.iloc[:, [-1]].astype('int')\n",
    "\n",
    "X_val = df_validation.iloc[:, 0:-1]\n",
    "y_val = df_validation.iloc[:, [-1]].astype('int')\n",
    "\n",
    "train = MD(X_train, y_train)\n",
    "val = MD(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=128)\n",
    "val_loader = DataLoader(val, batch_size=128)\n",
    "\n",
    "net = MLP().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_epoch(net, device, train_loader,\n",
    "                            F.nll_loss, optimizer)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{EPOCHS} Training Loss: {train_loss:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.967\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        X, y = data\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        output = net(X)\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
