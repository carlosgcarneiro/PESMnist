{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/balieiro/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.arff import loadarff \n",
    "\n",
    "from sklearn.model_selection import(\n",
    "    train_test_split, \n",
    "    cross_val_predict,\n",
    "    KFold,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import (\n",
    "    Dataset, \n",
    "    DataLoader,\n",
    "    TensorDataset,\n",
    "    random_split,\n",
    "    SubsetRandomSampler,\n",
    "    ConcatDataset,\n",
    ")\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU HELL YEAH!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling on GPU, babe\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "        print('Rolling on GPU, babe')\n",
    "        return device\n",
    "    print('CPU it is...')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, fc1, fc2):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28*28, fc1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc1, fc2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc2, 10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.model(x), dim=1)\n",
    "\n",
    "    def reset(self):\n",
    "        return self.model.apply(self.weight_reset)\n",
    "\n",
    "    def weight_reset(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            m.reset_parameters()\n",
    "\n",
    "def run_epoch(net, device, dataloader, \n",
    "              loss_fn, optimizer=None):\n",
    "    train = False if optimizer is None else True\n",
    "    net.train() if train else net.eval()\n",
    "\n",
    "    correct = 0\n",
    "    loss_arr = list()\n",
    "    for X, y in dataloader:\n",
    "        y = y.type(torch.LongTensor)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        output = net(X)\n",
    "        scores, predictions = torch.max(output.data, 1)\n",
    "        loss = loss_fn(output, y)\n",
    "        correct += (predictions == y).sum().item()\n",
    "        loss_arr.append(loss.item())\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return loss_arr, correct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming pd.DataFrame to torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDtoTensor(Dataset):\n",
    " \n",
    "  def __init__(self, X, y):\n",
    "    self.X_train = torch.tensor(X.values, dtype=torch.float)\n",
    "    self.y_train = torch.tensor(y.values.flatten(), dtype=torch.float)\n",
    " \n",
    "  def __len__(self):\n",
    "    return len(self.y_train)\n",
    "   \n",
    "  def __getitem__(self,idx):\n",
    "    return self.X_train[idx], self.y_train[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(X, y, train_idx, test_idx, batch_size=128):\n",
    "    train = PDtoTensor(X.iloc[train_idx], y.iloc[train_idx])\n",
    "    test = PDtoTensor(X.iloc[test_idx], y.iloc[test_idx])\n",
    "\n",
    "    train_loader = DataLoader(train, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "    \n",
    "def kfold_train(net: MLP, kf, epochs, X, y):\n",
    "    scores = list()\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):  \n",
    "        train_loader, test_loader = prepare_dataloader(X, y, train_idx, test_idx, 256)\n",
    "\n",
    "        optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_correct = run_epoch(\n",
    "                net,\n",
    "                device,\n",
    "                train_loader,\n",
    "                nn.CrossEntropyLoss(), \n",
    "                optimizer\n",
    "            )\n",
    "            test_loss, test_correct = run_epoch(\n",
    "                net,\n",
    "                device,\n",
    "                test_loader,\n",
    "                nn.CrossEntropyLoss(), \n",
    "                optimizer=None,\n",
    "            )\n",
    "        \n",
    "        test_acc = test_correct / len(test_loader.sampler)\n",
    "\n",
    "        scores.append(test_acc)\n",
    "        net.reset()\n",
    "\n",
    "    print(f'Accuracy mean (std): {np.mean(scores):.4f} ({np.std(scores):.4f})')\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "raw_data = loadarff('mnist_784.arff')\n",
    "df = pd.DataFrame(raw_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "Training with 10-fold CV for evaluation and 10 Epochs as a fixed hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mean (std): 0.9720 (0.0026)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9766666666666667,\n",
       " 0.9687301587301588,\n",
       " 0.9692063492063492,\n",
       " 0.9728571428571429,\n",
       " 0.9717460317460317,\n",
       " 0.9726984126984127,\n",
       " 0.9685714285714285,\n",
       " 0.9753968253968254,\n",
       " 0.9722222222222222,\n",
       " 0.9715873015873016]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separando dataset\n",
    "X = df.iloc[:, 0:-1]\n",
    "y = df.iloc[:, [-1]].astype('int')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "EPOCHS = 10\n",
    "\n",
    "# Training the model\n",
    "net = MLP(500,500).to(device)\n",
    "kfold_train(net, kf, EPOCHS, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "Treinando em 90% dos dados e utilizando 10% para validar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50 Training Loss: 0.424\n",
      "Epoch: 2/50 Training Loss: 0.191\n",
      "Epoch: 3/50 Training Loss: 0.132\n",
      "Epoch: 4/50 Training Loss: 0.116\n",
      "Epoch: 5/50 Training Loss: 0.104\n",
      "Epoch: 6/50 Training Loss: 0.093\n",
      "Epoch: 7/50 Training Loss: 0.080\n",
      "Epoch: 8/50 Training Loss: 0.070\n",
      "Epoch: 9/50 Training Loss: 0.061\n",
      "Epoch: 10/50 Training Loss: 0.053\n",
      "Epoch: 11/50 Training Loss: 0.045\n",
      "Epoch: 12/50 Training Loss: 0.039\n",
      "Epoch: 13/50 Training Loss: 0.033\n",
      "Epoch: 14/50 Training Loss: 0.028\n",
      "Epoch: 15/50 Training Loss: 0.023\n",
      "Epoch: 16/50 Training Loss: 0.018\n",
      "Epoch: 17/50 Training Loss: 0.014\n",
      "Epoch: 18/50 Training Loss: 0.012\n",
      "Epoch: 19/50 Training Loss: 0.010\n",
      "Epoch: 20/50 Training Loss: 0.008\n",
      "Epoch: 21/50 Training Loss: 0.006\n",
      "Epoch: 22/50 Training Loss: 0.005\n",
      "Epoch: 23/50 Training Loss: 0.004\n",
      "Epoch: 24/50 Training Loss: 0.004\n",
      "Epoch: 25/50 Training Loss: 0.003\n",
      "Epoch: 26/50 Training Loss: 0.003\n",
      "Epoch: 27/50 Training Loss: 0.002\n",
      "Epoch: 28/50 Training Loss: 0.002\n",
      "Epoch: 29/50 Training Loss: 0.002\n",
      "Epoch: 30/50 Training Loss: 0.001\n",
      "Epoch: 31/50 Training Loss: 0.001\n",
      "Epoch: 32/50 Training Loss: 0.001\n",
      "Epoch: 33/50 Training Loss: 0.001\n",
      "Epoch: 34/50 Training Loss: 0.001\n",
      "Epoch: 35/50 Training Loss: 0.000\n",
      "Epoch: 36/50 Training Loss: 0.000\n",
      "Epoch: 37/50 Training Loss: 0.000\n",
      "Epoch: 38/50 Training Loss: 0.000\n",
      "Epoch: 39/50 Training Loss: 0.000\n",
      "Epoch: 40/50 Training Loss: 0.000\n",
      "Epoch: 41/50 Training Loss: 0.000\n",
      "Epoch: 42/50 Training Loss: 0.000\n",
      "Epoch: 43/50 Training Loss: 0.000\n",
      "Epoch: 44/50 Training Loss: 0.000\n",
      "Epoch: 45/50 Training Loss: 0.000\n",
      "Epoch: 46/50 Training Loss: 0.000\n",
      "Epoch: 47/50 Training Loss: 0.000\n",
      "Epoch: 48/50 Training Loss: 0.000\n",
      "Epoch: 49/50 Training Loss: 0.000\n",
      "Epoch: 50/50 Training Loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "# Validations\n",
    "train = PDtoTensor(X_train, y_train)\n",
    "val = PDtoTensor(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=128)\n",
    "val_loader = DataLoader(val, batch_size=128)\n",
    "\n",
    "net = MLP(500,500).to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
    "\n",
    "for epoch in range(50):\n",
    "    train_loss, train_correct = run_epoch(\n",
    "        net,\n",
    "        device,\n",
    "        train_loader,\n",
    "        nn.CrossEntropyLoss(), \n",
    "        optimizer\n",
    "    )\n",
    "    print(f'Epoch: {epoch+1}/{50} Training Loss: {train_loss[-2]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.976\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        X, y = data\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        output = net(X)\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
